{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://habr.com/ru/all/'\n",
    "KEYWORDS = ['python', 'парсинг','Роскосмос','Лауреат','туннелей']\n",
    "times_,links_,titles_ = [],[],[]\n",
    "def search_match(KEYWORDS, string):\n",
    "    \"\"\"\n",
    "    Функция на вход принимает список слов и строку в которой надо искать. \n",
    "    Перебирает слова и возвращает True или False\n",
    "    \"\"\"\n",
    "    for word in KEYWORDS:\n",
    "        if word.lower() in string:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def search_full_text(link,key=KEYWORDS):\n",
    "    \"\"\"\n",
    "    Если не нашли в превью, переходим по ссылке и ищем в полном тексте новости\n",
    "    \"\"\"\n",
    "    req_1 = requests.get(link)\n",
    "    time.sleep(0.2)\n",
    "    html = BeautifulSoup(req_1.text, 'html.parser')\n",
    "    txt = html.find('div', id = 'post-content-body')\n",
    "    #Ищем совпадения с помощью функции search_match\n",
    "    return search_match(key, txt.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_habr(link,KEYWORDS):\n",
    "    \"\"\"\n",
    "    Функция на вход получает ссылку и список ключевых слов, \n",
    "    после чего ищет пересечение в заголовках и текстах новостей\n",
    "    \"\"\"\n",
    "    req = requests.get(link)\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    \n",
    "    #парсим страницу с самыми свежими новостями и берем превьюхи\n",
    "    preview = soup.find_all('article', class_ = 'post_preview')\n",
    "    \n",
    "    #Запускаем цикл для поиска в каждой новости\n",
    "    for post in preview:\n",
    "        #Достаем текст новости\n",
    "        texts = post.find('div',class_ = 'post__text')\n",
    "        #Достаем заголовок новости\n",
    "        title = post.find('a', class_= 'post__title_link')\n",
    "        #Время\n",
    "        time = post.find('span', class_ = 'post__time')\n",
    "        #Ссылка\n",
    "        link_full = post.find('a', class_= 'post__title_link')\n",
    "        link = link_full['href']\n",
    "        \n",
    "        #Проверяем с помощью функции search_match заголовок и текст новости в превью\n",
    "        if (search_match(KEYWORDS, title.text.lower()) or search_match(KEYWORDS, texts.text.lower())):\n",
    "#             print(title.text) для проверки\n",
    "            \n",
    "            #Добавляем в списки, если нашли\n",
    "            times_.append(time.text)\n",
    "            links_.append(link)\n",
    "            titles_.append(title.text)\n",
    "        #Если не находим в превью, переходим по ссылке и ищем в тексте   \n",
    "        elif search_full_text(link,KEYWORDS):\n",
    "            #print('full' + title.text) для проверки\n",
    "            times_.append(time.text)\n",
    "            links_.append(link)\n",
    "            titles_.append(title.text)\n",
    "        else:\n",
    "            pass\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Время</th>\n",
       "      <th>Ссылка</th>\n",
       "      <th>Заголовок</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>сегодня в 20:58</td>\n",
       "      <td>https://habr.com/ru/post/507608/</td>\n",
       "      <td>Визуализация при помощи генеративных алгоритмо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>сегодня в 16:59</td>\n",
       "      <td>https://habr.com/ru/company/piter/blog/522420/</td>\n",
       "      <td>Нобелевский лауреат по (математике?) о «Моде, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>сегодня в 16:45</td>\n",
       "      <td>https://habr.com/ru/post/522396/</td>\n",
       "      <td>ipipou: больше чем просто нешифрованный туннель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>сегодня в 16:32</td>\n",
       "      <td>https://habr.com/ru/company/fgts/blog/522432/</td>\n",
       "      <td>Удаленная работа или обзор VPN в Sophos XG Fir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Время                                          Ссылка  \\\n",
       "0  сегодня в 20:58                https://habr.com/ru/post/507608/   \n",
       "1  сегодня в 16:59  https://habr.com/ru/company/piter/blog/522420/   \n",
       "2  сегодня в 16:45                https://habr.com/ru/post/522396/   \n",
       "3  сегодня в 16:32   https://habr.com/ru/company/fgts/blog/522432/   \n",
       "\n",
       "                                           Заголовок  \n",
       "0  Визуализация при помощи генеративных алгоритмо...  \n",
       "1  Нобелевский лауреат по (математике?) о «Моде, ...  \n",
       "2    ipipou: больше чем просто нешифрованный туннель  \n",
       "3  Удаленная работа или обзор VPN в Sophos XG Fir...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_habr(link,KEYWORDS)\n",
    "#Создаем датафрейм на основе списков\n",
    "df = pd.DataFrame()\n",
    "df['Время'] = times_\n",
    "df['Ссылка'] = links_\n",
    "df['Заголовок'] = titles_\n",
    "df.head(30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL = ['eeee@e.ru', 'oooo@o.com']\n",
    "link = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "req = requests.post(link, json = {'emailAddresses': EMAIL}, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем таблицу соответствия емейла и веток\n",
    "xx = (req.json()['summary'])\n",
    "mail, breaches = [],[]\n",
    "\n",
    "#Добавляем в списки\n",
    "for x,y in xx.items():\n",
    "    for br in y['breaches']:\n",
    "        mail.append(x)\n",
    "        breaches.append(br)\n",
    "        \n",
    "#Создаем dataframe      \n",
    "mail_br = pd.DataFrame()\n",
    "mail_br['E-mail'] = mail\n",
    "mail_br['breaches'] = breaches\n",
    "\n",
    "#Переводим номера веток в строку, т.к. по умолчанию там np.int64\n",
    "mail_br['breaches'] = mail_br['breaches'].apply(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем вторую таблицу с описанием\n",
    "breaches = pd.DataFrame(req.json()['breaches']).transpose().reset_index()\n",
    "#Джойним таблицы\n",
    "total = breaches.rename(columns={'index' : 'breaches'}).merge(mail_br, on='breaches', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E-mail</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>site</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2019-11-14T00:00:00Z</td>\n",
       "      <td>toondo.com</td>\n",
       "      <td>In July 2019, the online comic creation site T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2019-08-08T00:00:00Z</td>\n",
       "      <td>poshmark.com</td>\n",
       "      <td>In May 2018, \"gently-used\" fashion retailer Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2016-10-24T00:00:00Z</td>\n",
       "      <td>dropbox.com</td>\n",
       "      <td>Cloud storage company Dropbox suffered a major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2017-05-04T00:00:00Z</td>\n",
       "      <td>uuu9.com</td>\n",
       "      <td>On an unconfirmed date, UUU9's user database w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2017-06-01T00:00:00Z</td>\n",
       "      <td>taobao.com</td>\n",
       "      <td>In January 2016, chinese online shopping site ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eeee@e.ru</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2017-04-14T00:00:00Z</td>\n",
       "      <td>17173.com</td>\n",
       "      <td>On an unconfirmed date, Chinese gaming site 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2017-03-01T00:00:00Z</td>\n",
       "      <td>heroesofnewerth.com</td>\n",
       "      <td>In December 2012, the online MMOG Heroes of Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2020-09-10T00:00:00Z</td>\n",
       "      <td>na</td>\n",
       "      <td>This is a compilation of files including breac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oooo@o.com</td>\n",
       "      <td>2017-09-07T00:00:00Z</td>\n",
       "      <td>tgbus.com</td>\n",
       "      <td>On an unconfirmed date, Chinese video gate sit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        E-mail           publishDate                 site  \\\n",
       "0   oooo@o.com  2019-11-14T00:00:00Z           toondo.com   \n",
       "1   oooo@o.com  2019-08-08T00:00:00Z         poshmark.com   \n",
       "2   oooo@o.com  2016-10-24T00:00:00Z          dropbox.com   \n",
       "3   oooo@o.com  2017-05-04T00:00:00Z             uuu9.com   \n",
       "4   oooo@o.com  2017-06-01T00:00:00Z           taobao.com   \n",
       "5    eeee@e.ru  2016-10-29T00:00:00Z               vk.com   \n",
       "6   oooo@o.com  2017-04-14T00:00:00Z            17173.com   \n",
       "7   oooo@o.com  2017-03-01T00:00:00Z  heroesofnewerth.com   \n",
       "8   oooo@o.com  2016-10-21T00:00:00Z            adobe.com   \n",
       "9   oooo@o.com  2020-09-10T00:00:00Z                   na   \n",
       "10  oooo@o.com  2017-09-07T00:00:00Z            tgbus.com   \n",
       "\n",
       "                                          description  \n",
       "0   In July 2019, the online comic creation site T...  \n",
       "1   In May 2018, \"gently-used\" fashion retailer Po...  \n",
       "2   Cloud storage company Dropbox suffered a major...  \n",
       "3   On an unconfirmed date, UUU9's user database w...  \n",
       "4   In January 2016, chinese online shopping site ...  \n",
       "5   Popular Russian social networking platform VKo...  \n",
       "6   On an unconfirmed date, Chinese gaming site 17...  \n",
       "7   In December 2012, the online MMOG Heroes of Ne...  \n",
       "8   In October of 2013, criminals penetrated Adobe...  \n",
       "9   This is a compilation of files including breac...  \n",
       "10  On an unconfirmed date, Chinese video gate sit...  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.iloc[:, [-1,-2,-5,-3]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
